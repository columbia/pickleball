# PickleBall

TODO: remove this link and replace with Zenodo artifact.
This artifact is hosted anonymously at: https://anonymous.4open.science/r/pickleball
See the link for the full repository.

PickleBall protects users who load untrusted pickle-based machine learning
models. The pickle serialization format permits arbitrary function invocations,
which attackers abuse by invoking malicious payloads when the model is loaded.

PickleBall ensures that the when the model is loaded, it may only invoke functions
necessary for loading. PickleBall infers the necessary functions by analyzing the
source code of the machine learning library used to create and load the model.

To use PickleBall, you must know the library that produced the model (often the
same as the library used to load the model) and the Python class definition of the
model.

PickleBall works in two steps:
1. Policy inference: generate a model loading policy.
2. Policy enforcement: enforce a model loading policy.

You only need to infer a policy once per machine learning library. After a
policy is generated, it can be used to load models using the library loading
API.

When you load a model, you will use PickleBall's loader to enforce the
generated policy.

For more details see our paper
[PickleBall: Secure Deserialization of Pickle-based Machine Learning Models](https://www.arxiv.org/abs/2508.15987),
appearing in the proceedings of the 2025 ACM CCS conference.

## Note to Artifact Evaluators

This top-level README provides general instructions for how to use PickleBall.
To specifically reproduce the results of the PickleBall paper, see:

* `evaluation/README.md`: instructions for reproducing the PickleBall evaluation
  (Section 6 of paper)
* `surveys/README.md`: instructions for reproducing the survey of the Hugging
  Face ecosystem (Section 3.1 and 3.2 of paper)

## Overview

PickleBall is composed of two components:
1. Policy Generator
2. Policy Enforcer

The Policy Generator receives (1) the source code of an ML library and (2) the
class definition in the library to analyze. It outputs a policy for safely loading
the class.

The Policy Enforcer replaces the `pickle` module on the system. It receives (1) an
ML model and (2) the loading policy. It loads the model while enforcing the given
policy.

### Policy Generator

The Policy Generator is executed off-line. The analysis entrypoint is the
`pickleball-generate.py` executable, which collects user arguments and invokes the
analysis steps. The `analyze/analyze.sc` script performs PickleBall's analysis and
outputs a policy as a JSON file.

### Policy Enforcer

The Policy Executor is executed on-line to load a model. It is implemented in the
`enforce/enforce.py`, which is a modified version of the Pickle Machine and serves
as a drop-in replacement. We provide Dockerfiles (`enforce/Dockerfile`) for
configuring an environment to use the module.

Primary components:

* `pickleball-generate.py`: the entry-point to PickleBall's analysis. It
  collects arguments and invokes the analysis.
* `analyze/analyze.sc`: PickleBall's policy generation analysis. Implemented as
  a Joern script in Scala. This is invoked with Joern by `pickleball-generate.py`
  and outputs a policy as a JSON file.
* `enforce/enforce.py`: PickleBall's policy enforcement. Implemented as
  modifications to the Pickle Machine and serves as a drop in replacement. We
  provide Dockerfiles for configuring an environment to use the module. Reads
  policies generated by `analyze.sc`.

### Analyzing a Library

TODO

## Evaluation

### Evaluation Setup

TODO: Move to `evaluation/README.md`

Create a .env file that defines the following environment variables:

```
BENIGN_MODELS=<path to benign model dataset>
MALICIOUS_MODELS=<path to malicious model dataset>
DATASETS=<path to evaluation datasets>
```

Build all evaluation containers:

```
$ docker compose build
```

Generate policies for evaluation dataset:

```
$ docker compose run generate-all
```

Policies will be output in the `evaluation/policies` directory.

Enforce policies:

```
$ docker compose run enforce-all
```

Load time performance experiment:

```
$ mkdir results
$ scripts/run-load-time.sh
$ python3 scripts/analyze_load_times.py
```

This will produce a table showing the load time overheads of the PickleBall loader. To rerun this experiment, delete the file at `results/times.csv` and rerun the above scripts.

## Run Joern tests

In the policy generation docker container:

```
# python3 runtests.py
```

## Troubleshooting

### Joern crash

Non-determinism in Joern may result in a crash on some executions. If one
occurs, first try re-executing Joern. If this occurs while running the inference
test suite, first re-execute the test suite. You can also run individual tests
by providing them as arguments by name with the `--fixtures` option. List all
available tests with the `--list` option.
