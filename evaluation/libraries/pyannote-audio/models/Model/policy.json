{"pyannote/audio/models/embedding/wespeaker/__init__.py:<module>.WeSpeakerResNet34":{"globals":["torch.torch_version.TorchVersion","torch.float8_e4m3fnuz","pyannote.audio.models.embedding.wespeaker.resnet.ResNet.__init__","pyannote.audio.tasks.segmentation.multilabel.MultiLabelSegmentation.prepare_chunk","pyannote.audio.core.task.Specifications.__len__","torch._utils._rebuild_nested_tensor","pathlib.Path.__init__","torch.complex32","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.validation_step","pyannote.audio.utils.receptive_field.conv1d_receptive_field_size","pyannote.audio.models.embedding.wespeaker.resnet.ResNet.num_frames","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.collate_fn","torch.BoolStorage","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.train__len__","torch.DoubleStorage","pyannote.audio.tasks.separation.PixIT.PixIT.val__iter__helper","torch.uint16","pyannote.audio.tasks.segmentation.multilabel.MultiLabelSegmentation.post_prepare_data","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.prepare_validation","typing.Literal","pyannote.audio.tasks.separation.PixIT.PixIT.train__iter__helper","pyannote.audio.core.model.Model.prepare_data","pyannote.audio.tasks.separation.PixIT.PixIT.training_step","pyannote.audio.tasks.separation.PixIT.PixIT.validation_step","pyannote.audio.models.embedding.wespeaker.resnet.ResNet34.<returnValue>.receptive_field_center","pyannote.audio.tasks.segmentation.overlapped_speech_detection.OverlappedSpeechDetection","pyannote.audio.models.embedding.wespeaker.resnet.ResNet._make_layer","pyannote.audio.core.task.Specifications.__init__","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.collate_X","torch.per_channel_affine_float_qparams","pyannote.audio.core.model.Model.__init__","torch.ShortStorage","types.MethodType.__init__","torch._utils._rebuild_parameter_with_state","asteroid.losses.MixITLossWrapper.__init__","pyannote.audio.core.io.Audio.__init__","torch.bits2x4","pyannote.audio.tasks.separation.PixIT.PixIT","pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization.__init__","pyannote.audio.models.embedding.wespeaker.__init__.BaseWeSpeakerResNet.__init__","torch.uint64","pyannote.audio.core.task.Task.val_monitor","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.val__len__","pyannote.audio.tasks.segmentation.multilabel.MultiLabelSegmentation.training_step","pyannote.audio.tasks.segmentation.multilabel.MultiLabelSegmentation.val_monitor","pyannote.pipeline.parameter.Uniform.__init__","pyannote.audio.models.embedding.wespeaker.resnet.ResNet34.<returnValue>.receptive_field_size","pyannote.audio.tasks.segmentation.voice_activity_detection.VoiceActivityDetection.__init__","torch._utils._rebuild_tensor_v2","pyannote.audio.core.task.Task.collate_fn","pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization.prepare_chunk","y_pred.shape.<returnValue>.<member>(shape).<indexAccess>","pyannote.audio.models.embedding.wespeaker.resnet.ResNet.forward","torch.Size","typing.Dict","pyannote.audio.core.model.Model.on_save_checkpoint","builtins.bytearray","pyannote.audio.core.model.Model.task","diarization.shape.<returnValue>.<member>(shape).<indexAccess>","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.val__getitem__","torch._utils._rebuild_sparse_tensor","pyannote.audio.core.model.Model.freeze_by_name","pyannote.audio.tasks.segmentation.voice_activity_detection.VoiceActivityDetection","pyannote.audio.tasks.segmentation.mixins.Task","torch.HalfStorage","torch.ComplexFloatStorage","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.num_chunks_per_class","pyannote.audio.core.task.Task.default_loss","pyannote.audio.core.task.Task.__init__","pyannote.audio.core.task.Task.metric","pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization","pyannote.audio.pipelines.utils.get_augmentation","pyannote.audio.core.task.Problem","torch.nn.parameter.Parameter","pyannote.audio.core.task.Task.post_prepare_data","pyannote.audio.core.task.Task.prepare_data","pyannote.audio.core.task.Specifications","pyannote.audio.utils.powerset.Powerset.__init__","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.get_file","pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization.setup_loss_func","pyannote.audio.models.embedding.wespeaker.__init__.BaseWeSpeakerResNet.forward_embedding","typing.Union","pyannote.audio.core.model.Model.__example_input_array","torch._utils._rebuild_wrapper_subclass","pyannote.audio.tasks.separation.PixIT.PixIT.__init__","torch.Tensor","pyannote.audio.core.task.Task.setup","torch.LongStorage","_codecs.encode","pyannote.audio.pipelines.speaker_verification.SpeechBrainPretrainedSpeakerEmbedding.metric","pyannote.audio.models.embedding.wespeaker.resnet.ResNet152.<returnValue>.receptive_field_size","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.collate_meta","pyannote.audio.core.task.Resolution","pyannote.audio.models.embedding.wespeaker.resnet.ResNet152","pyannote.audio.core.model.Model.default_activation","pyannote.audio.tasks.segmentation.overlapped_speech_detection.OverlappedSpeechDetection.prepare_chunk","pyannote.audio.core.task.Task.val_dataloader","pyannote.audio.tasks.separation.PixIT.PixIT.default_metric","torch.device","pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization.default_metric","pyannote.audio.models.embedding.wespeaker.resnet.ResNet293","pyannote.audio.core.model.Model.training_step","torch.TypedStorage","pyannote.audio.core.task.Task.val__len__","pyannote.audio.models.embedding.wespeaker.__init__.BaseWeSpeakerResNet.compute_fbank","torch.QUInt2x4Storage","pyannote.audio.models.embedding.wespeaker.resnet.ResNet.forward_frames","pyannote.audio.models.embedding.wespeaker.__init__.BaseWeSpeakerResNet.fbank_only","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.collate_fn","torch._utils._rebuild_device_tensor_from_numpy","typing.Protocol","pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization.voice_activity_detection_loss","pyannote.audio.tasks.separation.PixIT.PixIT.prepare_chunk","pyannote.audio.tasks.segmentation.multilabel.MultiLabelSegmentation.validation_step","pyannote.audio.models.embedding.wespeaker.resnet.ResNet221.<returnValue>.receptive_field_size","pyannote.audio.models.embedding.wespeaker.__init__.WeSpeakerResNet34.__init__","pyannote.audio.tasks.segmentation.voice_activity_detection.VoiceActivityDetection.prepare_chunk","pyannote.audio.core.model.Model.freeze_up_to","pyannote.audio.core.task.Task.setup_loss_func","torch.per_channel_symmetric","torch.float8_e4m3fn","pyannote.audio.core.task.Task.train__len__","pyannote.audio.tasks.embedding.arcface.SupervisedRepresentationLearningWithArcFace.__init__","pyannote.audio.core.task.Task.train__iter__","torch_audiomentations.core.transforms_interface.BaseWaveformTransform","typing.Protocol.<operator>.tupleLiteral.<returnValue>.<indexAccess>","torch.float8_e5m2fnuz","functools.lru_cache","torch.per_channel_affine","pyannote.audio.core.model.Model.specifications","torch.CharStorage","torch.bits8","torch.QInt32Storage","pyannote.audio.pipelines.speaker_verification.NeMoPretrainedSpeakerEmbedding.metric","collections.Counter","torch._utils._rebuild_parameter","torch.ByteStorage","pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization.segmentation_loss","pyannote.audio.tasks.separation.PixIT.PixIT.collate_fn","numpy.sum","pyannote.audio.core.task.Task.common_step","pyannote.audio.tasks.segmentation.multilabel.MultiLabelSegmentation.__init__","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.default_metric","pyannote.audio.tasks.separation.PixIT.PixIT.val_dataloader","collections.OrderedDict","torch._tensor._rebuild_from_type_v2","pyannote.audio.models.embedding.wespeaker.__init__.WeSpeakerResNet34","torch.FloatStorage","pyannote.audio.pipelines.speaker_verification.ONNXWeSpeakerPretrainedSpeakerEmbedding.metric","torch._utils._rebuild_tensor","pyannote.audio.core.model.Model.forward","pyannote.audio.tasks.embedding.arcface.SupervisedRepresentationLearningWithArcFace","functools.cached_property","pyannote.audio.core.task.Task.val__getitem__","pyannote.audio.tasks.embedding.arcface.SupervisedRepresentationLearningWithArcFace.setup_loss_func","torch.nn.serialization._get_layout","pyannote.audio.core.model.Model.configure_optimizers","pyannote.pipeline.parameter.Categorical.__init__","torch._utils._rebuild_tensor_v3","pyannote.audio.tasks.separation.PixIT.PixIT.val__iter__","torch.bits4x2","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.batch_size","pyannote.audio.models.embedding.wespeaker.__init__.BaseWeSpeakerResNet.forward","pyannote.audio.models.embedding.wespeaker.resnet.ResNet152.<returnValue>.receptive_field_center","pyannote.audio.core.model.Model.val_dataloader","pyannote.audio.core.model.Model.on_load_checkpoint","pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization.setup","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.train__iter__","pyannote.audio.models.embedding.wespeaker.resnet.ResNet.receptive_field_center","pyannote.audio.models.embedding.wespeaker.resnet.ResNet","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.val__getitem__","pyannote.audio.tasks.segmentation.multilabel.MultiLabelSegmentation","pyannote.audio.core.model.Model.receptive_field","torch._utils._rebuild_device_tensor_from_cpu_tensor","torch.uint32","pyannote.audio.core.task.Task.default_metric","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.train__iter__helper","pyannote.audio.tasks.separation.PixIT.PixIT.common_step","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.train__iter__","pyannote.audio.models.embedding.wespeaker.__init__.BaseWeSpeakerResNet.receptive_field_center","pyannote.audio.models.embedding.wespeaker.resnet.ResNet221","torch.float8_e5m2","pyannote.audio.core.model.Model.from_pretrained","pyannote.audio.core.task.Specifications.powerset","torch.IntStorage","pyannote.audio.models.embedding.wespeaker.resnet.ResNet221.<returnValue>.receptive_field_center","pyannote.audio.core.model.Model.train_dataloader","pyannote.audio.core.model.Model.example_input_array","torch.QUInt4x2Storage","torch.bits1x8","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.val__len__","torch.per_tensor_symmetric","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.setup","pyannote.audio.core.task.Task.specifications","pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization.collate_y","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.train__len__","pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization.training_step","pyannote.audio.core.task.Task.training_step","pyannote.audio.core.model.Model.__up_to","pyannote.audio.core.task.Task.validation_step","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.validation_step","pyannote.audio.core.model.Model.unfreeze_up_to","pyannote.audio.core.task.Task","pyannote.audio.core.model.Model.__by_name","torch.UntypedStorage","pyannote.audio.core.task.Task.setup_validation_metric","pyannote.audio.models.embedding.wespeaker.__init__.BaseWeSpeakerResNet.num_frames","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.num_classes_per_batch","torch._utils._rebuild_qtensor","torch.nn.Module","prediction.shape.<returnValue>.<member>(shape).<indexAccess>","pyannote.audio.tasks.separation.PixIT.PixIT.create_mixtures_of_mixtures","pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization.validation_step","pyannote.audio.models.embedding.wespeaker.resnet.ResNet.forward_embedding","pyannote.audio.core.task.Task.train_dataloader","pyannote.audio.models.embedding.wespeaker.__init__.BaseWeSpeakerResNet.dimension","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.prepare_validation","pyannote.audio.core.task.Specifications.num_powerset_classes","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.default_metric","pyannote.audio.tasks.separation.PixIT.PixIT.collate_y","pyannote.audio.core.task.Specifications.__iter__","pyannote.audio.tasks.segmentation.multilabel.MultiLabelSegmentation.setup","pyannote.audio.models.embedding.wespeaker.resnet.ResNet293.<returnValue>.receptive_field_center","pyannote.audio.core.model.Model.unfreeze_by_name","typing.Optional","torch.BFloat16Storage","pyannote.audio.models.embedding.wespeaker.__init__.BaseWeSpeakerResNet.receptive_field_size","pyannote.audio.pipelines.speaker_verification.PyannoteAudioPretrainedSpeakerEmbedding.metric","functools.partial","pyannote.audio.core.model.Model.validation_step","pyannote.audio.tasks.segmentation.mixins.SegmentationTask","torch.QInt8Storage","torch.QUInt8Storage","pyannote.audio.models.embedding.wespeaker.__init__.BaseWeSpeakerResNet.forward_frames","pyannote.audio.tasks.segmentation.mixins.SegmentationTask.collate_y","torch.per_tensor_affine","pyannote.audio.tasks.separation.PixIT.PixIT.common__iter__helper","pyannote.audio.core.model.Model.setup","typing.Protocol.<indexAccess>","pyannote.audio.tasks.separation.PixIT.PixIT.segmentation_loss","torch.bits16","torch.ComplexDoubleStorage","pyannote.audio.tasks.segmentation.overlapped_speech_detection.OverlappedSpeechDetection.__init__","pyannote.audio.models.embedding.wespeaker.resnet.ResNet293.<returnValue>.receptive_field_size","pyannote.audio.models.embedding.wespeaker.resnet.ResNet34","pyannote.audio.tasks.separation.PixIT.PixIT.setup","torch._utils._rebuild_meta_tensor_no_storage","pyannote.audio.core.model.Model.build","pyannote.audio.tasks.embedding.mixins.SupervisedRepresentationLearningTaskMixin.training_step","pyannote.audio.models.embedding.wespeaker.resnet.ResNet.receptive_field_size","collections.defaultdict"],"reduces":["torch._utils._rebuild_tensor_v2","torch.Size","torch._utils._rebuild_wrapper_subclass","torch.device","torch._utils._rebuild_device_tensor_from_numpy","torch.float8_e4m3fnuz","torch.per_tensor_symmetric","torch.BFloat16Storage","torch._utils._rebuild_meta_tensor_no_storage","torch._utils._rebuild_nested_tensor","torch.complex32","torch.BoolStorage","torch.DoubleStorage","torch.uint16","torch.ShortStorage","torch._utils._rebuild_parameter_with_state","torch.per_channel_affine_float_qparams","torch.bits2x4","torch.uint64","builtins.bytearray","torch.ComplexFloatStorage","torch._utils._rebuild_sparse_tensor","torch.HalfStorage","pyannote.audio.core.task.Problem","torch.nn.parameter.Parameter","torch.Tensor","torch.LongStorage","pyannote.audio.core.task.Resolution","_codecs.encode","torch.TypedStorage","torch.QUInt2x4Storage","torch.per_channel_symmetric","torch.float8_e4m3fn","torch.CharStorage","torch.float8_e5m2fnuz","torch.per_channel_affine","torch.bits8","torch.QInt32Storage","collections.Counter","torch._utils._rebuild_parameter","torch.ByteStorage","collections.OrderedDict","torch._tensor._rebuild_from_type_v2","torch.FloatStorage","torch._utils._rebuild_tensor","torch.nn.serialization._get_layout","torch._utils._rebuild_tensor_v3","torch.bits4x2","torch.uint32","torch._utils._rebuild_device_tensor_from_cpu_tensor","torch.float8_e5m2","torch.IntStorage","torch.QUInt4x2Storage","torch.bits1x8","torch._utils._rebuild_qtensor","torch.UntypedStorage","torch.QInt8Storage","torch.QUInt8Storage","torch.per_tensor_affine","torch.bits16","torch.ComplexDoubleStorage"]}}
